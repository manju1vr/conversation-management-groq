# ================================
# ðŸ”¹ Setup
# ================================

!pip install openai requests

import openai
import json
import requests

# Configure API key (Replace with your Groq key)
openai.api_key = "YOUR_GROQ_API_KEY"   # <--- Put your key here
openai.api_base = "https://api.groq.com/openai/v1"


# ================================
# ðŸ”¹ Task 1: Conversation Management
# ================================

conversation_history = []
run_count = 0
k = 3   # summarize after every 3rd run


def add_message(role, content):
    """Add message to history"""
    conversation_history.append({"role": role, "content": content})


def get_truncated_history(limit_type="turns", limit_value=3):
    """Truncate history by turns or words"""
    if limit_type == "turns":
        return conversation_history[-limit_value:]
    elif limit_type == "words":
        text = " ".join([msg["content"] for msg in conversation_history])
        return text.split()[-limit_value:]
    return conversation_history


def summarize_history():
    """Summarize entire conversation so far using Groq"""
    messages = [{"role": "system", "content": "Summarize the following conversation concisely."}]
    messages += conversation_history
    
    response = openai.ChatCompletion.create(
        model="llama3-8b-8192",  # Groq-compatible model
        messages=messages,
        max_tokens=100
    )
    return response.choices[0].message["content"]


def chat_with_summarization(user_input):
    """Simulate chatting + auto-summarize after k runs"""
    global run_count
    add_message("user", user_input)
    run_count += 1

    # Assistant response (demo â€” here just echo)
    response = f"Echo: {user_input}"
    add_message("assistant", response)

    # Summarize every k-th run
    if run_count % k == 0:
        summary = summarize_history()
        print(f"\nðŸ”¹ Auto-Summary after {run_count} runs:\n{summary}\n")

    return response


# ðŸ”¹ Demo for Task 1
print("=== Task 1: Conversation Management ===")
print(chat_with_summarization("Hi Assistant!"))
print(chat_with_summarization("What's the weather like?"))
print(chat_with_summarization("Tell me about Python."))   # summary here

print("\nðŸ”¹ Last 2 turns:\n", get_truncated_history("turns", 2))
print("\nðŸ”¹ Last 10 words:\n", get_truncated_history("words", 10))



# ================================
# ðŸ”¹ Task 2: JSON Schema Extraction
# ================================

schema = {
    "name": "extract_user_info",
    "description": "Extract user details from conversation",
    "parameters": {
        "type": "object",
        "properties": {
            "name": {"type": "string", "description": "User's full name"},
            "email": {"type": "string", "description": "User's email"},
            "phone": {"type": "string", "description": "User's phone number"},
            "location": {"type": "string", "description": "User's location"},
            "age": {"type": "integer", "description": "User's age"}
        },
        "required": ["name", "email", "phone", "location", "age"]
    }
}


def extract_info(chat_text):
    """Extract user info using Groq structured outputs"""
    response = openai.ChatCompletion.create(
        model="llama3-8b-8192",
        messages=[{"role": "user", "content": chat_text}],
        functions=[schema],
        function_call={"name": "extract_user_info"}
    )
    return response.choices[0].message["function_call"]["arguments"]


# ðŸ”¹ Demo for Task 2
print("\n=== Task 2: JSON Extraction ===")
samples = [
    "Hi, I am John Doe. You can reach me at john@example.com, my phone is 1234567890. I live in New York and I am 25 years old.",
    "My name is Alice Brown, email alice.b@gmail.com, phone +91-9876543210, I live in Bangalore, Iâ€™m 30.",
    "Iâ€™m Sam, 40 years old, from London. Email: sam40@mail.com, phone: 555-777-999."
]

for chat in samples:
    print("\nChat:", chat)
    print("Extracted:", extract_info(chat))

