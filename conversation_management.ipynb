{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNpYxSQCGWiiOs9BtxlUvjL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["libraries"],"metadata":{"id":"1CwNK6t15xA4"}},{"cell_type":"code","execution_count":51,"metadata":{"id":"HjqpPAel5Hg7","executionInfo":{"status":"ok","timestamp":1758204473551,"user_tz":-330,"elapsed":7048,"user":{"displayName":"Manjunath Reddy v","userId":"00651502746711721239"}}},"outputs":[],"source":["# Cell 0 — install what's needed\n","!pip install requests jsonschema --quiet"]},{"cell_type":"markdown","source":["Set your API key safely"],"metadata":{"id":"O_gt6MWQ6FHD"}},{"cell_type":"code","source":["# Cell 1 — enter your Groq API key safely (it won't print)\n","from getpass import getpass\n","import os\n","\n","GROQ_API_KEY = getpass(\"Paste your Groq API key (won't show): \")\n","os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n","\n","# Groq's OpenAI-compatible base URL\n","GROQ_BASE = \"https://api.groq.com/openai/v1\"\n","\n","# Quick check (do not print key)\n","print(\"API key loaded into session. GROQ_BASE is set.\")\n"],"metadata":{"id":"2CNKj3k15qcw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Small helper to call Groq with requests"],"metadata":{"id":"JKAHiPP_6Hwd"}},{"cell_type":"code","source":["# Cell 2 — helper for calling the Groq OpenAI-compatible chat/completions endpoint\n","import requests, json, time\n","\n","HEADERS = {\n","    \"Authorization\": f\"Bearer {os.environ.get('GROQ_API_KEY')}\",\n","    \"Content-Type\": \"application/json\"\n","}\n","\n","def groq_chat_request(messages, model=\"llama3-8b-8192\", functions=None, function_call=None, temperature=0.2, max_tokens=512):\n","    payload = {\n","        \"model\": model,\n","        \"messages\": messages,\n","        \"temperature\": temperature,\n","        \"max_tokens\": max_tokens\n","    }\n","    if functions is not None:\n","        payload[\"functions\"] = functions\n","    if function_call is not None:\n","        payload[\"function_call\"] = function_call\n","\n","    resp = requests.post(f\"{GROQ_BASE}/chat/completions\", headers=HEADERS, json=payload)\n","    resp.raise_for_status()\n","    return resp.json()"],"metadata":{"id":"CJg-yVTx5-IB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ConversationHistory class"],"metadata":{"id":"5Gq-HzzK6bJS"}},{"cell_type":"code","source":["# Cell 3 — conversation history manager with truncation and summary replacement\n","from typing import List, Dict, Optional\n","\n","class ConversationHistory:\n","    def __init__(self):\n","        self.history: List[Dict[str,str]] = []   # list of {role, content}\n","        self.run_count = 0\n","\n","    def add_message(self, role: str, content: str):\n","        self.history.append({\"role\": role, \"content\": content})\n","\n","    def last_n_turns(self, n: int) -> List[Dict[str,str]]:\n","        # Return last n messages (user+assistant messages counted individually)\n","        return self.history[-n:] if n > 0 else []\n","\n","    def truncate_by_chars(self, max_chars: int) -> List[Dict[str,str]]:\n","        # Keep most recent messages until the char budget is filled\n","        total = 0\n","        selected = []\n","        for msg in reversed(self.history):\n","            l = len(msg['content'])\n","            if total + l > max_chars:\n","                break\n","            selected.insert(0, msg)\n","            total += l\n","        return selected\n","\n","    def replace_with_summary(self, summary_text: str, upto_index: Optional[int] = None):\n","        # Replace history up to upto_index (exclusive) with a single system summary\n","        if upto_index is None:\n","            upto_index = len(self.history)\n","        remaining = self.history[upto_index:]\n","        self.history = [{\"role\":\"system\", \"content\": \"Conversation summary:\\n\" + summary_text}] + remaining\n","\n","    def show(self):\n","        print(\"---- Conversation history ----\")\n","        for i, m in enumerate(self.history):\n","            role = m['role']\n","            content = m['content']\n","            print(f\"{i:02d} | {role}: {content}\")\n","        print(\"-----------------------------\")\n"],"metadata":{"id":"-PaQB4jR6bjp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LLM summarization & fallback"],"metadata":{"id":"1xZEAbS66cB8"}},{"cell_type":"code","source":["# Cell 4 — LLM summarization wrapper plus a tiny fallback\n","def build_summary_prompt(messages: List[Dict[str,str]]) -> str:\n","    lines = []\n","    for m in messages:\n","        lines.append(f\"[{m['role']}] {m['content']}\")\n","    messages_text = \"\\n\".join(lines)\n","    prompt = (\n","        \"You are a helpful assistant. Summarize the conversation below in 2-3 short sentences, \"\n","        \"mentioning main requests and any user info (name, email, phone, location, age) if present.\\n\\n\"\n","        f\"{messages_text}\\n\\nSummary:\"\n","    )\n","    return prompt\n","\n","def llm_summarize(messages_slice: List[Dict[str,str]], model=\"llama3-8b-8192\"):\n","    # Build a single user prompt message sent to model\n","    prompt = build_summary_prompt(messages_slice)\n","    payload_messages = [{\"role\":\"user\", \"content\": prompt}]\n","    try:\n","        resp = groq_chat_request(payload_messages, model=model, temperature=0.0, max_tokens=256)\n","        choice = resp['choices'][0]\n","        summary_text = choice['message']['content'].strip()\n","        return summary_text\n","    except Exception as e:\n","        print(\"LLM summarization failed:\", e)\n","        # fallback: extract last 2 user messages\n","        user_texts = [m['content'] for m in messages_slice if m['role']=='user']\n","        fallback = \"Recent user notes: \" + \" | \".join(user_texts[-2:])\n","        return fallback"],"metadata":{"id":"amNww6Ly6ccC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Periodic summarization runner"],"metadata":{"id":"VoLwQNAM6y_x"}},{"cell_type":"code","source":["# Cell 5 — function to add a user turn and periodically summarize after every k runs\n","def run_user_turn(conv: ConversationHistory, user_text: str, assistant_text_fn=None, k: int=3, truncation_mode: str='turns', truncation_value: int=6):\n","    \"\"\"\n","    conv: ConversationHistory\n","    user_text: new user message (string)\n","    assistant_text_fn: optional function that takes user_text and returns assistant response string\n","                       if None, assistant reply will be simple echo.\n","    k: summarize every k runs (periodic summarization)\n","    truncation_mode: 'turns' or 'chars'\n","    truncation_value: if turns -> last n messages used for summary; if chars -> max chars used\n","    \"\"\"\n","    conv.run_count += 1\n","    conv.add_message('user', user_text)\n","\n","    # create assistant reply (here: simple echo, or call the model if you like)\n","    if assistant_text_fn is None:\n","        assistant_reply = \"Assistant: got your message - \" + (user_text[:120])\n","    else:\n","        assistant_reply = assistant_text_fn(user_text)\n","    conv.add_message('assistant', assistant_reply)\n","\n","    # Periodic summarization\n","    if conv.run_count % k == 0:\n","        # choose slice for summarization\n","        if truncation_mode == 'turns':\n","            slice_msgs = conv.last_n_turns(truncation_value)\n","        else:\n","            slice_msgs = conv.truncate_by_chars(truncation_value)\n","        print(f\">>> Running summarization at run {conv.run_count} (k={k}) - using {truncation_mode}={truncation_value}\")\n","        summary = llm_summarize(slice_msgs)\n","        conv.replace_with_summary(summary)   # replace older content with the summary\n","\n","    return assistant_reply\n"],"metadata":{"id":"_lwRR6rZ65RP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Task 1 — feed multiple samples & show different truncations"],"metadata":{"id":"bPvzT_SS6-DM"}},{"cell_type":"code","source":["# Cell 6 — Demo for Task 1\n","conv = ConversationHistory()\n","\n","samples = [\n","    \"Hi, I'm Anu. My email is anu@example.com and I live in Pune.\",\n","    \"I would like to upgrade to premium subscription.\",\n","    \"Also, can you export my chat history and billing info?\",\n","    \"I am 31 years old and my phone number is +919876543210.\",\n","    \"What is the refund policy if I cancel within 7 days?\",\n","    \"Can you provide invoice for last month?\",\n","    \"Thanks, I need it by next Monday.\"\n","]\n","\n","# run through messages, summarizing every 3 runs (k=3), using last 6 messages for the summary\n","for i, msg in enumerate(samples, start=1):\n","    reply = run_user_turn(conv, msg, k=3, truncation_mode='turns', truncation_value=6)\n","    print(f\"Run {i} assistant reply: {reply}\")\n","    conv.show()\n","    print(\"\\n---\\n\")\n","\n","# Now try again using char truncation for comparison\n","print(\"Now demo truncation by chars (max 180 chars for summary slice).\")\n","conv2 = ConversationHistory()\n","for i, msg in enumerate(samples, start=1):\n","    _ = run_user_turn(conv2, msg, k=3, truncation_mode='chars', truncation_value=180)\n","conv2.show()"],"metadata":{"id":"wodpp2j37INV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Task 2 — JSON schema + function-calling definition"],"metadata":{"id":"ss5_ox5Y7Lwo"}},{"cell_type":"code","source":["# Cell 7 — JSON schema and function definition (OpenAI-style) for extracting 5 fields\n","CONTACT_SCHEMA = {\n","    \"type\":\"object\",\n","    \"properties\":{\n","        \"name\": {\"type\":\"string\"},\n","        \"email\": {\"type\":[\"string\",\"null\"]},\n","        \"phone\": {\"type\":[\"string\",\"null\"]},\n","        \"location\": {\"type\":[\"string\",\"null\"]},\n","        \"age\": {\"type\":[\"integer\",\"null\"]}\n","    },\n","    \"required\": [\"name\"]\n","}\n","\n","# Function spec to pass to the model\n","FUNCTIONS = [\n","    {\n","        \"name\": \"extract_contact\",\n","        \"description\": \"Extract contact fields from a chat message\",\n","        \"parameters\": {\n","            \"type\": \"object\",\n","            \"properties\": {\n","                \"name\": {\"type\":\"string\", \"description\":\"Full name if present\"},\n","                \"email\": {\"type\":\"string\", \"description\":\"Email address or null\"},\n","                \"phone\": {\"type\":\"string\", \"description\":\"Phone number or null\"},\n","                \"location\": {\"type\":\"string\", \"description\":\"City or location or null\"},\n","                \"age\": {\"type\":\"integer\", \"description\":\"Age in years or null\"}\n","            },\n","            \"required\": [\"name\"]\n","        }\n","    }\n","]\n"],"metadata":{"id":"ujK-ZrVL7YX5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper to call function-calling and parse results"],"metadata":{"id":"THe8qSl77WbG"}},{"cell_type":"code","source":["# Cell 8 — function-calling helper that asks model to run extract_contact and returns parsed JSON\n","def extract_contact_via_model(sample_chat: str, model=\"llama3-8b-8192\"):\n","    messages = [\n","        {\"role\":\"system\", \"content\":\"You are a JSON parser. Extract user info into the function arguments exactly.\"},\n","        {\"role\":\"user\", \"content\": sample_chat}\n","    ]\n","    try:\n","        resp = groq_chat_request(messages, model=model, functions=FUNCTIONS, function_call={\"name\":\"extract_contact\"}, temperature=0.0, max_tokens=256)\n","        choice = resp['choices'][0]\n","        # The model should return function_call arguments\n","        if 'message' in choice and 'function_call' in choice['message']:\n","            args_text = choice['message']['function_call']['arguments']\n","            parsed = json.loads(args_text)\n","            return parsed, resp\n","        # fallback: try parsing content\n","        if 'message' in choice and 'content' in choice['message']:\n","            try:\n","                parsed = json.loads(choice['message']['content'])\n","                return parsed, resp\n","            except Exception:\n","                return None, resp\n","    except Exception as e:\n","        print(\"Model call failed:\", e)\n","        return None, {}"],"metadata":{"id":"Nb5tagmp7hv0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Task 2 — parse 3 sample chats and validate"],"metadata":{"id":"Ej2gMNET7ntD"}},{"cell_type":"code","source":["# Cell 9 — run extraction on 3 sample chats and validate using jsonschema\n","from jsonschema import validate, ValidationError\n","samples = [\n","    \"Hello, I'm Priya R. My email is priya.r@example.com and I live in Bangalore. I'm 27.\",\n","    \"Hi, it's Raj. Phone: +919876543210. I don't have an email listed.\",\n","    \"Name: John Doe; Age: 45; Location: New York; Contact: john.doe@example.com, +1-415-555-0123\"\n","]\n","\n","results = []\n","for s in samples:\n","    parsed, raw = extract_contact_via_model(s)\n","    print(\"Sample:\", s)\n","    print(\"Parsed (raw):\", parsed)\n","    if parsed:\n","        try:\n","            # Ensure age is integer or null\n","            if parsed.get(\"age\") is not None and isinstance(parsed.get(\"age\"), str) and parsed.get(\"age\").isdigit():\n","                parsed[\"age\"] = int(parsed[\"age\"])\n","            validate(instance=parsed, schema=CONTACT_SCHEMA)\n","            print(\"Validation: OK\")\n","        except ValidationError as ve:\n","            print(\"Validation error:\", ve.message)\n","    else:\n","        print(\"No parsed JSON returned.\")\n","    print(\"\\n---\\n\")\n","    results.append({\"sample\": s, \"parsed\": parsed})\n","\n","# Show final results list\n","print(\"All results:\", results)"],"metadata":{"id":"4eDEIcRy7xbD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save notebook and push to GitHub (safe workflow)"],"metadata":{"id":"ocC4JuK78RAJ"}},{"cell_type":"code","source":["# 1. Check the file exists\n","!ls -lh /content\n","\n","# 2. Go to content folder\n","%cd /content\n","\n","# 3. Configure git (only first time, replace with your details)\n","!git config --global user.email \"you@example.com\"\n","!git config --global user.name \"Your Name\"\n","\n","# 4. Initialize git (safe even if already initialized)\n","!git init\n","\n","# 5. Reset and add remote (to avoid 'remote origin already exists' error)\n","!git remote remove origin || true\n","!git remote add origin https://github.com/manju1vr/conversation-management-groq.git\n","\n","# 6. Add your notebook\n","!git add \"conversation_management.ipynb\"\n","\n","# 7. Commit it\n","!git commit -m \"Add conversation management notebook\"\n","\n","# 8. Make sure branch is main\n","!git branch -M main\n","\n","# 9. Push to GitHub\n","!git push -u origin main\n"],"metadata":{"id":"I-SQIgXMDDSF"},"execution_count":null,"outputs":[]}]}